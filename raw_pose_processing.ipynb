{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Poses from Amass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/PriorMDM/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please remember to download the following subdataset from AMASS website: https://amass.is.tue.mpg.de/download.php. Note only download the <u>SMPL+H G</u> data.\n",
    "* ACCD (ACCD)\n",
    "* HDM05 (MPI_HDM05)\n",
    "* TCDHands (TCD_handMocap)\n",
    "* SFU (SFU)\n",
    "* BMLmovi (BMLmovi)\n",
    "* CMU (CMU)\n",
    "* Mosh (MPI_mosh)\n",
    "* EKUT (EKUT)\n",
    "* KIT  (KIT)\n",
    "* Eyes_Janpan_Dataset (Eyes_Janpan_Dataset)\n",
    "* BMLhandball (BMLhandball)\n",
    "* Transitions (Transitions_mocap)\n",
    "* PosePrior (MPI_Limits)\n",
    "* HumanEva (HumanEva)\n",
    "* SSM (SSM_synced)\n",
    "* DFaust (DFaust_67)\n",
    "* TotalCapture (TotalCapture)\n",
    "* BMLrub (BioMotionLab_NTroje)\n",
    "\n",
    "### Unzip all datasets. In the bracket we give the name of the unzipped file folder. Please correct yours to the given names if they are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place all files under the directory **./amass_data/**. The directory structure shoud look like the following:  \n",
    "./amass_data/  \n",
    "./amass_data/ACCAD/  \n",
    "./amass_data/BioMotionLab_NTroje/  \n",
    "./amass_data/BMLhandball/  \n",
    "./amass_data/BMLmovi/   \n",
    "./amass_data/CMU/  \n",
    "./amass_data/DFaust_67/  \n",
    "./amass_data/EKUT/  \n",
    "./amass_data/Eyes_Japan_Dataset/  \n",
    "./amass_data/HumanEva/  \n",
    "./amass_data/KIT/  \n",
    "./amass_data/MPI_HDM05/  \n",
    "./amass_data/MPI_Limits/  \n",
    "./amass_data/MPI_mosh/  \n",
    "./amass_data/SFU/  \n",
    "./amass_data/SSM_synced/  \n",
    "./amass_data/TCD_handMocap/  \n",
    "./amass_data/TotalCapture/  \n",
    "./amass_data/Transitions_mocap/  \n",
    "\n",
    "**Please make sure the file path are correct, otherwise it can not succeed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device to run the body model on.\n",
    "comp_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n"
     ]
    }
   ],
   "source": [
    "from my_smpl import MySMPL\n",
    "\n",
    "body_model = MySMPL(\"body_models/smpl\", gender=\"neutral\", ext=\"pkl\").to(comp_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "input_dir='dataset/aist/rotations/'\n",
    "output_dir='dataset/aist/new_joints/'\n",
    "output_dir2='dataset/aist/motion_database/'\n",
    "os.makedirs(output_dir,exist_ok=True)\n",
    "os.makedirs(output_dir2,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.1002\n"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "import json\n",
    "ex_fps = 60\n",
    "with open(\"dataset/aist/scaling.txt\")as f:\n",
    "    id2scale={}\n",
    "    for line in f.readlines():\n",
    "        k,v=line.strip().split()\n",
    "        v=float(v)\n",
    "        id2scale[k]=v\n",
    "print(id2scale[\"gBR_sBM_cAll_d04_mBR0_ch02\"])\n",
    "def amass_to_pose(src_path, save_path, save_path2, scale):\n",
    "    rotations=np.load(src_path)\n",
    "    head_pos=np.load(src_path.replace(\"part\",\"root\"))/scale\n",
    "    assert rotations.shape[0]==head_pos.shape[0]\n",
    "    with torch.no_grad():\n",
    "        global_orient = torch.tensor(rotations[:,:3], dtype=torch.float32).to(comp_device) # controls the global root orientation\n",
    "        body_pose = torch.tensor(rotations[:,3:], dtype=torch.float32).to(comp_device)\n",
    "        head_pos = torch.tensor(head_pos, dtype=torch.float32).to(comp_device)  \n",
    "        body = body_model(body_pose=body_pose, global_orient=global_orient)\n",
    "        joints = body.joints+(head_pos-body.joints[:,15]).unsqueeze(dim=1)\n",
    "        joints = joints[:,:22].cpu().numpy()\n",
    "    floor_height = joints.min(axis=0).min(axis=0)[1]\n",
    "    joints[:, :, 1] -= floor_height\n",
    "    root_pose_init_xz = joints[0,0] * np.float32([1, 0, 1])\n",
    "    joints = joints - root_pose_init_xz\n",
    "    np.save(save_path, joints)\n",
    "    out={\"root_positions\": binascii.b2a_base64(\n",
    "        joints[:,0].flatten().astype(np.float32).tobytes()).decode(\"utf-8\"),\n",
    "           \"rotations\": binascii.b2a_base64(rotations.flatten().astype(np.float32).tobytes()).decode(\n",
    "               \"utf-8\"),\n",
    "           \"dtype\": \"float32\",\n",
    "           \"fps\": 60,\n",
    "           \"mode\": \"axis_angle\",\n",
    "           \"n_frames\": rotations.shape[0],\n",
    "           \"n_joints\": 24}\n",
    "    with open(save_path2, \"w\") as f:\n",
    "        json.dump(out,f, indent=4)\n",
    "\n",
    "#amass_to_pose(input_dir+\"gBR_sBM_cAll_d04_mBR0_ch01/part_0.npy\", output_dir+\"aist_gBR_0.npy\", output_dir2+\"aist_gBR_0.json\", id2scale[\"gBR_sBM_cAll_d04_mBR0_ch01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a few hours for all datasets, here we take one dataset as an example\n",
    "\n",
    "To accelerate the process, you could run multiple scripts like this at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  9.62539554e-01  0.00000000e+00]\n",
      " [ 6.89899474e-02  8.74000907e-01  2.52156928e-02]\n",
      " [-6.59901351e-02  8.70687366e-01  7.70531595e-04]\n",
      " [ 3.38736176e-03  1.06396747e+00 -4.78853360e-02]\n",
      " [ 1.39923140e-01  5.06629348e-01  6.96647838e-02]\n",
      " [-6.97639361e-02  5.60965776e-01  2.28721835e-01]\n",
      " [ 2.11457908e-03  1.19719505e+00 -7.14192241e-02]\n",
      " [ 7.98219293e-02  1.92877173e-01 -1.72024779e-01]\n",
      " [-1.90642327e-02  1.64534926e-01  2.61054493e-01]\n",
      " [-1.34350359e-02  1.24759448e+00 -4.55850437e-02]\n",
      " [ 4.35162187e-02  8.80824327e-02 -9.62815583e-02]\n",
      " [-7.13228434e-02  1.33273482e-01  3.81337710e-01]\n",
      " [-5.07029295e-02  1.45860553e+00 -4.71442938e-03]\n",
      " [ 3.99623662e-02  1.37590218e+00  8.14872235e-03]\n",
      " [-9.85109732e-02  1.36722612e+00 -7.29220062e-02]\n",
      " [-8.15213695e-02  1.49395955e+00  6.37298748e-02]\n",
      " [ 9.23681110e-02  1.39777648e+00  8.59879926e-02]\n",
      " [-1.71095729e-01  1.39686704e+00 -1.37840554e-01]\n",
      " [ 1.02162808e-02  1.19080973e+00  2.22850628e-01]\n",
      " [-2.05817640e-01  1.22481632e+00 -3.22809778e-01]\n",
      " [-1.87033728e-01  1.33612227e+00  1.76200397e-01]\n",
      " [-2.26590276e-01  9.70440865e-01 -3.34214203e-01]]\n",
      "[[-0.56409897  0.87837565 -0.076611  ]\n",
      " [-0.55538078  0.79335701 -0.06786129]\n",
      " [-0.62527935  0.78209829 -0.08447879]\n",
      " [-0.58378457  0.98391449 -0.11075098]\n",
      " [-0.49735479  0.43300295  0.06966478]\n",
      " [-0.74582489  0.43021184 -0.06262736]\n",
      " [-0.53563742  1.11540926 -0.10652988]\n",
      " [-0.6728579   0.1019398  -0.17202478]\n",
      " [-0.96554519  0.10467553 -0.29359629]\n",
      " [-0.49752004  1.16117692 -0.07167043]\n",
      " [-0.60114415  0.         -0.12745108]\n",
      " [-1.0243655   0.00321507 -0.21255985]\n",
      " [-0.41607098  1.3641777  -0.03622768]\n",
      " [-0.40779914  1.29751337 -0.06618797]\n",
      " [-0.51904191  1.25987911 -0.07292201]\n",
      " [-0.36423928  1.39696646  0.0369859 ]\n",
      " [-0.35516703  1.29850686 -0.08977397]\n",
      " [-0.56786694  1.242715   -0.13784055]\n",
      " [-0.42490445  1.05140257 -0.29191329]\n",
      " [-0.71056081  0.99895525 -0.32389263]\n",
      " [-0.45078136  0.84026682 -0.3999274 ]\n",
      " [-0.92415889  0.7475667  -0.35404085]]\n"
     ]
    }
   ],
   "source": [
    "joints=np.load(output_dir+\"aist_gBR_1.npy\")\n",
    "print(joints[0])\n",
    "print(joints.min(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1408/1408 [00:03<00:00, 367.80it/s]\n"
     ]
    }
   ],
   "source": [
    "mid=0\n",
    "for path in tqdm(sorted(os.listdir(input_dir))):\n",
    "    for p in sorted(os.listdir(os.path.join(input_dir,path))):\n",
    "        if p.startswith(\"root_\"):continue\n",
    "        amass_to_pose(os.path.join(input_dir,path,p), output_dir+f\"aist_{path.split('_')[0]}_{mid}.npy\", \\\n",
    "                      output_dir2+f\"aist_{path.split('_')[0]}_{mid}.json\", id2scale[path])\n",
    "        mid+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will extract poses from **AMASS** dataset, and put them under directory **\"./pose_data\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source data from **HumanAct12** is already included in **\"./pose_data\"** in this repository. You need to **unzip** it right in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment, Mirror and Relocate Motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
