{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "\n",
    "from common.skeleton import Skeleton\n",
    "import numpy as np\n",
    "import os\n",
    "from common.quaternion import *\n",
    "from paramUtil import *\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import rotation_conversions as geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_idx1, l_idx2 = 5, 8\n",
    "# Right/Left foot\n",
    "fid_r, fid_l = [8, 11], [7, 10]\n",
    "# Face direction, r_hip, l_hip, sdr_r, sdr_l\n",
    "face_joint_indx = [2, 1, 17, 16]\n",
    "# l_hip, r_hip\n",
    "r_hip, l_hip = 2, 1\n",
    "joints_num = 22\n",
    "n_raw_offsets = torch.from_numpy(t2m_raw_offsets)\n",
    "kinematic_chain = t2m_kinematic_chain\n",
    "def process_file(positions, angle, feet_thre):\n",
    "\n",
    "    \"\"\" Get Foot Contacts \"\"\"\n",
    "    global_positions = positions.copy()\n",
    "\n",
    "    def foot_detect(positions, thres):\n",
    "        velfactor, heightfactor = np.array([thres, thres]), np.array([3.0, 2.0])\n",
    "\n",
    "        feet_l_x = (positions[1:, fid_l, 0] - positions[:-1, fid_l, 0]) ** 2\n",
    "        feet_l_y = (positions[1:, fid_l, 1] - positions[:-1, fid_l, 1]) ** 2\n",
    "        feet_l_z = (positions[1:, fid_l, 2] - positions[:-1, fid_l, 2]) ** 2\n",
    "        #     feet_l_h = positions[:-1,fid_l,1]\n",
    "        #     feet_l = (((feet_l_x + feet_l_y + feet_l_z) < velfactor) & (feet_l_h < heightfactor)).astype(np.float)\n",
    "        feet_l = ((feet_l_x + feet_l_y + feet_l_z) < velfactor).astype(np.float32)\n",
    "\n",
    "        feet_r_x = (positions[1:, fid_r, 0] - positions[:-1, fid_r, 0]) ** 2\n",
    "        feet_r_y = (positions[1:, fid_r, 1] - positions[:-1, fid_r, 1]) ** 2\n",
    "        feet_r_z = (positions[1:, fid_r, 2] - positions[:-1, fid_r, 2]) ** 2\n",
    "        #     feet_r_h = positions[:-1,fid_r,1]\n",
    "        #     feet_r = (((feet_r_x + feet_r_y + feet_r_z) < velfactor) & (feet_r_h < heightfactor)).astype(np.float)\n",
    "        feet_r = (((feet_r_x + feet_r_y + feet_r_z) < velfactor)).astype(np.float32)\n",
    "        return feet_l, feet_r\n",
    "    #\n",
    "    feet_l, feet_r = foot_detect(positions, feet_thre)\n",
    "\n",
    "    def get_cont6d_params(positions, angle):\n",
    "        cont_6d_params = geometry.matrix_to_rotation_6d(geometry.axis_angle_to_matrix(torch.tensor(angle))).numpy()\n",
    "        # skel = Skeleton(n_raw_offsets, kinematic_chain, \"cpu\")\n",
    "        # (seq_len, joints_num, 4)\n",
    "        # quat_params = skel.inverse_kinematics_np(positions, face_joint_indx, smooth_forward=True)\n",
    "        # (seq_len, 4)\n",
    "        # r_rot = quat_params[:, 0].copy()\n",
    "        r_rot=geometry.axis_angle_to_quaternion(torch.tensor(angle))[:,0].numpy()\n",
    "        \n",
    "        velocity = (positions[1:, 0] - positions[:-1, 0]).copy()\n",
    "        velocity = qrot_np(r_rot[1:], velocity)\n",
    "        r_velocity = qmul_np(r_rot[1:], qinv_np(r_rot[:-1]))\n",
    "        return cont_6d_params, r_velocity, velocity, r_rot\n",
    "    cont_6d_params, r_velocity, velocity, r_rot = get_cont6d_params(positions, angle)\n",
    "\n",
    "    def get_rifke(positions):\n",
    "        '''Local pose'''\n",
    "        positions[:,1:, 0] -= positions[:, 0:1, 0]\n",
    "        positions[:,1:, 2] -= positions[:, 0:1, 2]\n",
    "        return positions\n",
    "\n",
    "    '''Root height'''\n",
    "    positions = get_rifke(positions)\n",
    "    root_y = positions[:, 0, 1:2]\n",
    "\n",
    "    root_data = np.concatenate([positions[:-1,0], root_y[:-1]], axis=-1)\n",
    "\n",
    "    '''Get Joint Rotation Representation'''\n",
    "    # (seq_len, (joints_num-1) *6) quaternion for skeleton joints\n",
    "    rot_data = cont_6d_params[:, 1:].reshape(len(cont_6d_params), -1)\n",
    "\n",
    "    '''Get Joint Rotation Invariant Position Represention'''\n",
    "    # (seq_len, (joints_num-1)*3) local joint position\n",
    "    ric_data = positions[:, 1:].reshape(len(positions), -1)\n",
    "\n",
    "    '''Get Joint Velocity Representation'''\n",
    "    # (seq_len-1, joints_num*3)\n",
    "    local_vel = qrot_np(np.repeat(r_rot[:-1, None], global_positions.shape[1], axis=1),\n",
    "                        global_positions[1:] - global_positions[:-1])\n",
    "    local_vel = local_vel.reshape(len(local_vel), -1)\n",
    "\n",
    "    data = root_data\n",
    "    data = np.concatenate([data, ric_data[:-1]], axis=-1)\n",
    "    data = np.concatenate([data, rot_data[:-1]], axis=-1)\n",
    "    #     print(data.shape, local_vel.shape)\n",
    "    data = np.concatenate([data, local_vel], axis=-1)\n",
    "    data = np.concatenate([data, feet_l, feet_r], axis=-1)\n",
    "\n",
    "    return data, global_positions, positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover global angle and positions for rotation data\n",
    "# root_rot_velocity (B, seq_len, 1)\n",
    "# root_linear_velocity (B, seq_len, 2)\n",
    "# root_y (B, seq_len, 1)\n",
    "# ric_data (B, seq_len, (joint_num - 1)*3)\n",
    "# rot_data (B, seq_len, (joint_num - 1)*6)\n",
    "# local_velocity (B, seq_len, joint_num*3)\n",
    "# foot contact (B, seq_len, 4)\n",
    "def recover_root_rot_pos(data):\n",
    "    rot_vel = data[..., 0]\n",
    "    r_rot_ang = torch.zeros_like(rot_vel).to(data.device)\n",
    "    '''Get Y-axis rotation from rotation velocity'''\n",
    "    r_rot_ang[..., 1:] = rot_vel[..., :-1]\n",
    "    r_rot_ang = torch.cumsum(r_rot_ang, dim=-1)\n",
    "\n",
    "    r_rot_quat = torch.zeros(data.shape[:-1] + (4,)).to(data.device)\n",
    "    r_rot_quat[..., 0] = torch.cos(r_rot_ang)\n",
    "    r_rot_quat[..., 2] = torch.sin(r_rot_ang)\n",
    "\n",
    "    r_pos = torch.zeros(data.shape[:-1] + (3,)).to(data.device)\n",
    "    r_pos[..., 1:, [0, 2]] = data[..., :-1, 1:3]\n",
    "    '''Add Y-axis rotation to root position'''\n",
    "    r_pos = qrot(qinv(r_rot_quat), r_pos)\n",
    "\n",
    "    r_pos = torch.cumsum(r_pos, dim=-2)\n",
    "\n",
    "    r_pos[..., 1] = data[..., 3]\n",
    "    return r_rot_quat, r_pos\n",
    "\n",
    "\n",
    "def recover_from_rot(data, joints_num, skeleton):\n",
    "    r_rot_quat, r_pos = recover_root_rot_pos(data)\n",
    "\n",
    "    r_rot_cont6d = quaternion_to_cont6d(r_rot_quat)\n",
    "\n",
    "    start_indx = 1 + 2 + 1 + (joints_num - 1) * 3\n",
    "    end_indx = start_indx + (joints_num - 1) * 6\n",
    "    cont6d_params = data[..., start_indx:end_indx]\n",
    "    #     print(r_rot_cont6d.shape, cont6d_params.shape, r_pos.shape)\n",
    "    cont6d_params = torch.cat([r_rot_cont6d, cont6d_params], dim=-1)\n",
    "    cont6d_params = cont6d_params.view(-1, joints_num, 6)\n",
    "\n",
    "    positions = skeleton.forward_kinematics_cont6d(cont6d_params, r_pos)\n",
    "\n",
    "    return positions\n",
    "\n",
    "\n",
    "def recover_from_ric(data, joints_num):\n",
    "    r_rot_quat, r_pos = recover_root_rot_pos(data)\n",
    "    positions = data[..., 4:(joints_num - 1) * 3 + 4]\n",
    "    positions = positions.view(positions.shape[:-1] + (-1, 3))\n",
    "\n",
    "    '''Add Y-axis rotation to local joints'''\n",
    "    positions = qrot(qinv(r_rot_quat[..., None, :]).expand(positions.shape[:-1] + (4,)), positions)\n",
    "\n",
    "    '''Add root XZ to joints'''\n",
    "    positions[..., 0] += r_pos[..., 0:1]\n",
    "    positions[..., 2] += r_pos[..., 2:3]\n",
    "\n",
    "    '''Concate root and joints'''\n",
    "    positions = torch.cat([r_pos.unsqueeze(-2), positions], dim=-2)\n",
    "\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 22, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# The given data is used to double check if you are on the right track.\n",
    "import pickle\n",
    "input_dir_angle='dataset/inter-human/motions/'\n",
    "input_dir_pos='dataset/inter-human/new_joints/'\n",
    "output_dir='dataset/inter-human/new_joint_vecs/'\n",
    "os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "ex_fps = 20\n",
    "\n",
    "angle=pickle.load(open(input_dir_angle+\"123.pkl\",'rb'))\n",
    "fps = angle['mocap_framerate']\n",
    "down_sample = round(fps / ex_fps)\n",
    "bdata=angle[\"person1\"]\n",
    "angles=np.concatenate((bdata['root_orient'],bdata['pose_body']),axis=1)[::down_sample].reshape(-1,22,3)\n",
    "\n",
    "positions=pickle.load(open(input_dir_pos+\"123.pkl\",'rb'))[\"person1\"]\n",
    "print(positions.shape)\n",
    "vector=process_file(positions,angles,0.002)[0]\n",
    "print(vector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 7227/7227 [00:19<00:00, 377.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(os.listdir(input_dir_pos)):\n",
    "    try:\n",
    "        angle=pickle.load(open(input_dir_angle+path,'rb'))\n",
    "        fps = angle['mocap_framerate']\n",
    "        down_sample = round(fps / ex_fps)\n",
    "        positions=pickle.load(open(input_dir_pos+path,'rb'))\n",
    "        out={}\n",
    "        for person in [\"person1\",\"person2\"]:\n",
    "            bdata=angle[person]\n",
    "            rotations=np.concatenate((bdata['root_orient'],bdata['pose_body']),axis=1)[::down_sample].reshape(-1,22,3)\n",
    "            out[person]=process_file(positions[person],rotations,0.002)[0]\n",
    "        with open(output_dir+path,'wb') as f:\n",
    "            pickle.dump(out,f)\n",
    "    except:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve=pickle.load(open(output_dir+\"123.pkl\",'rb'))\n",
    "print(pe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
